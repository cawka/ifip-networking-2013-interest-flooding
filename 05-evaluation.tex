\section{Evaluation of Interest flooding mitigation methods}
\label{sec:evaluation}

% List all possible parameters, say clearly which ones we vary, and which ones we do not, along with explanations.

% Metrics that we will consider in our evaluation (Satisfaction rate for good clients, Link utilization near producers, 

% alex: what's a point of latency?  it would matter only for queueing method and we not really pushing this method
% Latency for good clients, good versus bad interests as a function of time

In this section, we present an in-depth evaluation study, aiming to quantify the effectiveness of all our Interest flooding attack mitigation methods.
We used the open-source ndnSIM~\cite{ndnsim} package, which implements NDN protocol stack for NS-3 network simulator (\url{http://www.nsnam.org/}), to run simulations for a variety of network topologies and scenarios. 
We extended ndnSIM with our three mitigation algorithms---token bucket with per interface fairness, satisfaction-based Interest acceptance, or satisfaction-based pushback---and evaluated effectiveness of each algorithm independently.

% For evaluating the effectiveness of each mitigation algorithm, every router in the simulated topology runs the mitigation algorithm under study.

% why we chose small scale topology
% what point we wanted to show we small scale
% what points we wanted to verify with larger-scale internet like topology

% Metrics
% not sure if i already explained that. our essential qualitative metric is .  
% To quantify the effectiveness of the mitigation mechanism this  metric we use satisfaction percentages of user Interests.

The metric we choose to quantify the effectiveness of our algorithms is the {\it percentage of satisfied Interests for legitimate users}. This metric corresponds to the quality of service experienced by legitimate users when the network is under attack. In other words, if the network implements a mitigation method $X$ and a high percentage of user-expressed Interests are satisfied even while the network is under attack, then one can conclude that method $X$ is highly effective at mitigating the attack. We also ensure that all Interests expressed by legitimate users during a period of no-attack are satisfied.
 
%Quality of the attack mitigation methods directly corresponds to the quality of service for the legitimate users during an ongoing attack, which in NDN network can be quantified through percentage of satisfied Interest.
%For example, if the network implements a mitigation method $X$ and under the attack majority of user-expressed Interests are getting satisfied, then the method $X$ can be seen as highly effective.
%At the same time, if only a small percentage of the expressed Interest are getting satisfied during the attack, the method $X$ can be called ineffective. 

% Traffic pattern
In our experiments, we assume that legitimate users express Interests at constant average rates with randomized time gap between two consecutive Interests, where the random number for the gap follows a uniform distribution. We believe that this traffic pattern provides a reasonable approximation of traffic mix from all network users without excessive buffering. To quantify the behavior of our mitigation strategies under a worse case attack scenario, we ensure that all the attackers send junk Interests as fast as they can. 
%(remember, that Interest limits will not allow real flooding of Intersests in all of the designed mitigation algorithms).

% Alex: not sure how to argue about the traffic pattern
%Although this pattern may seem not truly realistic, it approximates a good statistical mix of traffic from all network users without excessive network buffering.

%In addition to that, in each run of the simulation we ensure that all Interests expressed by the legitimate users during a no-attack period are satisfied.
%For simplicity, we also equalized the average rates with which the legitimate users express Interests.
%At the same time, the attackers are sending junk Interests as much as they can get through (remember, that Interest limits will not allow real f%looding of Intersests in all of the designed mitigation algorithms).

We ran our simulations on two different network topologies---a smaller binary tree topology and a much larger ISP-like topology. We use a binary tree topology as it represents one of the worst cases to defend against Interest flooding DDoS attacks. The larger ISP topology reflects how our mitigation methods would perform when deployed on the real Internet.
Again, to study the performance of our mitigation strategies under a range of conditions, we also varied the percentage of attackers in the network---the values ranged from 6\% attackers to over 50\% attackers in the network.

% Fixed parameters
We set the \emph{delay} and \emph{data size} parameters for the Interest limit calculation to a fixed value for every node in the simulated topology. In particular, for the small-scale binary tree topology, we set delay to 80~ms, while for the large-scale ISP topology we set it to 330~ms (the order of the largest RTT). The data size is 1100~bytes for all simulation runs and topologies.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Small-scale evaluations}
\label{sec:small-scale}

% Topology description
%To assess baseline quality of the designed Interest flooding attack mitigation methods, we evaluated them first using a %simplistic small-scale binary tree topology 
In Fig.~\ref{fig:small-scale}, we depict the binary-tree topology that we used for our initial experiments.
Legitimate users as well as attackers were placed on leaf nodes (red nodes) as show in the figure. There are 16 end users (both legitimate and attackers) in this topology, each expressing Interests that are routed towards a single data producer placed at the root of the tree.  Each link in this topology is assigned a bandwidth of 10~Mbps and a randomized propagation delay ranging from 1 to 10 ms. 

% Alex: should we mention that?
%The main reason to chose a binary tree topology was that it represents one of the worst cases to defend against flooding DDoS %attacks.
%That is, sharing of the network links exponentially increases as decreasing level of the binary tree.

\begin{figure}[]
  \centering
  \includegraphics[scale=0.2]{topo-tree-evil-5-good-0-producer-gw}
  \caption{Small-scale binary tree topology}
  \label{fig:small-scale}
\end{figure}

% in 10 independent runs of each simulation, where we randomized position of the adversaries along the legitimate users.   In all runs, the total number of legitimate and malicious uses were fixed, meaning that when we increase number of attackers, we decrease the number of legitimate users.   

\subsubsection{Effectiveness of the three mitigation algorithms}

%The first set of experiments aims to evaluate reaction of the network and Interest flooding attack mitigation methods mechanisms under a moderate-level DDoS attack.
%For this purpose, we simulated four different network scenarios, in which all routers implements the same attack mitigation algorithm, either token bucket with per interface fairness, satisfaction-based Interest acceptance, or satisfaction-based pushback (Section~\ref{sec:design}).

Our goal is to compare the effectiveness of each mitigation method and quantify the percentage of Interests satisfied for all legitimate users while the network is under attack. For each mitigation algorithm, we perform 10 independent simulation runs, where we randomly choose 7 client nodes to represent adversaries while the remaining 9 client nodes represent legitimate users. In each run we simulate a 10-minute attack window (total simulation time was 30 minutes, with attack starting at the 10-minute mark). We plot the minimum and maximum range for observed Interest satisfaction percentages for all legitimate users aggregated across the 10 simulation runs as a function of time for each mitigation algorithm in Fig.~\ref{fig:small-scale attack progress}. Token bucket with per-interface fair queuing performs the worst, while satisfaction-based pushback performs the best, with almost a 100\%  satisfied Interests for all legitimate users.

%A short and simplistic summary of the results is that the first two attack mitigation methods do not work at all, and the last two are working quite good.

\begin{figure}[]
  \centering
  \hspace{-0.8cm}\includegraphics[scale=0.8]{paper-topo-tree/tree-good-0-producer-gw}
  \vspace{-.3cm}
  \caption{Interest satisfaction ratio as a function of time for binary-tree topology with 7 attackers and 9 legitimate users}
  \label{fig:small-scale attack progress}
  \vspace{-.4cm}
\end{figure}

%\paragraph{\textbf{Simple token bucket}}

%{\color{red}Alex: should this discussion be removed or we still want to keep it (as it is referenced later and potentially before)}

%Let us take a deeper look on what is happening with the simple token bucket algorithm.
%Essentially, we observe an extremely successful denial of service attack, where attackers almost completely shut down legitimate users from the Data producer (using a relatively small amount of Interests, as token bucket restricts the number of forwarded Intersets!).
%This ``success'' can be explained using a simplistic example, illustrated on Fig.~\ref{fig:three router example}, where each router has only one token for Interest forwarding.
%In this example we assume that both the legitimate user and the adversary send Interests in about the same time.
%
%\begin{figure}[t]
%  \centering
%  \includegraphics[scale=0.3]{physical-limits-sync-problem}
%  \caption{Three-router topology, with one legitimate and one malicious user}
%  \label{fig:three router example}
%\end{figure}
%
%Both router L and router X will forward the Interests, as both of them have a free token available.
%At router A, two cases are possible, either of Interests can arrive first, resulting in a quite different effects.
%When legitimate Interest arrives first, then there are no problem. 
%Router A will capture the token, forward the Interest, which will be quickly satisfied, releasing the token for future uses.
%In the mean time, malicious Interest will be dropped at router A, and router X will release the hold for the token in one second (i.e., after the maximum time Interests are admitted), enabling a new round of competition for router A's resources.
%
%In the case when malicious Interest is sent a little bit earlier, then router A will forward malicious Interests, dropping a legitimate one, and causing ``lock out'' for one second.
%In the instant when the token gets released at router X, an adversary is able to push new Interest towards router A, which may arrive in the exact time A's token gets released (assuming an idealistic environment).
%As a result, the adversary recaptures router A's token and extends the ``lock out'' for another second, denying service to the legitimate user without sending any massive numbers of Interests.

\paragraph{\textbf{Token bucket with per interface fairness}}

We observe a successful DDoS attack, where 40\% attackers succeed in significantly shutting down the remaining 60\% legitimate users---a mere 15\% of their Interests are satisfied by Data from the producer. Contrary to expectations, the 60\% legitimate users do not receive at least 60\% of network resources. As described in the previous section, the key limitation of this algorithm is that it still admits Interests from attackers, a good percentage of which traverse all the way to the data producer. Significantly reducing the number of accepted malicious Interests is fundamental for improving the effectiveness of any mitigation algorithm. 

%The described problem arises from the clocking effect and can be solved in a number different ways.
%Augmenting token bucket algorithms with per-interface fair queueing allows us to eliminate the clocking effect. 
%That is, in the second case when router A releases the token after the first ``lock out'' period, it will immediately process previously enqueued Interests from the legitimate user.
%However, because the Interest time out (``lock out'' time) is most likely be larger than the time to actually fetch the Data, an adversary is still able to ``unfairly'' deny service to good guys.
%Ideally, if there are only 40\% of compromised users, the rest good users should get at least 60\% of network resources, which is not true as can be seen on Fig.~\ref{fig:small-scale attack progress}.
%We expect that reducing the maximum hold time for Interests (e.g., to an order of average RTT) would improve overall performance for legitimate users, with negative effect of requiring extra complexity for Intersets processing.

\paragraph{\textbf{Satisfaction-based Interest acceptance}}

The effectiveness of this algorithm stems from the fact that routers do not admit malicious Interests into the network, thereby ensuring availability of network resources for serving legitimate users. The observed periodic dips in the Interest satisfaction ratios of legitimate users in Fig.~\ref{fig:small-scale attack progress} is a direct result of Interest satisfaction rate statistics decaying with time. The 50-second period approximately corresponds to the selected exponential decaying parameter $\alpha=e^{−1.0/30.0}$, which decays statistics to $1/e$ of the initial value that ranges from 30~seconds to 50~seconds. 
%The primary reason that such minimum peaks exist is the fact that 
When Interests from attackers start to get readmitted, they cause degradation of statistics on routers close to the producer (i.e., routers that observe traffic mix from legitimate and malicious users). Consequently, this degradation reduces the probability of legitimate Interests getting through (see Section~\ref{sec:probabilistic}) until malicious Interests are ``pushed back'' to the edge.

%When routers more intelligently process incoming Interests (i.e., based on the incoming interface statistics), the Interest flooding attack becomes virtually ineffective.
%That is, malicious Interests are simply not getting admitted to the network, not being able to create much service disturbance for the legitimate users.

\paragraph{\textbf{Satisfaction-based pushback}}

This mitigation algorithm is able to effectively shut down attackers and ensure that almost all of the Interests from legitimate users are satisfied. 
%The only potential problem with the satisfaction-based pushback algorithm is that it features 
We observe a  sharp dip in the satisfaction ratio curve at the start of the attack.  It takes a few seconds for all routers to be fully aware of the attack, which happens when malicious Interests start to time out and explicit Interest limit announcements succeed in containing malicious Interests close to the attacker. Till then, the network for a short period of time (under 10~seconds for all simulation runs), fails to provide 100\% service for legitimate users. Once the malicious Interests are effectively shut down, all Interests from legitimate users are satisfied. Unlike the satisfaction-based Interest acceptance scenario, we do not observe any periodic dips in the satisfaction curve, as the pushback algorithm effectively guarantees that once an Interest is admitted, it will almost certainly be routed to the data producer.

\subsubsection{Network reaction with to varying number of attackers}

Our next goal is to study the effectiveness of our mitigation algorithms as a function of increasing adversaries in the network.
To this end, we vary the percentage of attackers in the topology from 6\% to over 50\%. Since the total number of end users in the topology is constant, as the number of attackers increases, the number of legitimate users decreases. All other parameters and experimental set-up are similar to the previous experiment. As before, for each mitigation algorithm, we perform 10 independent simulation runs.
%The second set of conducted experiments was aimed to answer the question of the effect and quality of the Interest flooding attack mitigation algorithm under different attack volume.
%To do this, for each algorithm we varied the number of adversary nodes in the topology, keeping the total number of client nodes constant: 1 attacker and 15 legitimate users, 3 attackers and 13 legitimate users, etc.

%Since at this point the overall attack dynamics of all the attack mitigation algorithms is relatively clear, 
% In other words, each point captured in the box plot graph corresponds to 1-second averaged satisfaction ratio for a user in an individual simulation run.

\begin{figure}[htbp]
  \centering
  \includegraphics[scale=0.8]{paper-topo-tree/tree-good-0-producer-gw-avg-1-min}
  \vspace{-.3cm}
  \caption{Average Interest satisfaction ratios for the first minute of the experiment as a function of increasing attackers in the network}\vspace{-.1cm}
  \label{fig:small-scale-topo boxplot}
\end{figure}

In Fig.\ref{fig:small-scale-topo boxplot} we present  the Interest satisfaction ratio for legitimate users aggregated over the 10 simulation runs for the first minute of the attack. The results are as expected---for all three mitigation algorithms, as the percentage of attackers in the network increases, the lower is the Interest satisfaction ratio for legitimate users.
In the case of token bucket with per-interface fairness algorithm, just 3 attackers can halve the quality of service for the remaining 13 legitimate users. While both intelligent attack mitigation algorithms also show a decline in service quality as the percentage of attackers increases, this decline is much more gradual and marginal. In the case of satisfaction-based pushback algorithm, over 90\% of Interests from legitimate users are satisfied even when over 50\% of the users are malicious.  
 


% \begin{figure}[htbp]
%   \centering
%   \includegraphics[scale=0.9]{tree-topo-var-evils-max-consumers-30mins/tree-good-0-producer-gw-avg-1-min-after-1-min}
%   \caption{Average consumer Interest satisfaction ratios (second minute)}
%   \label{fig:small-scale-topo 2}
% \end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Large scale simulations}
\label{sec:largescale}

%To check validity of the small-scale experiment results, we performed a larger-scale evaluation based on a modified version of 

Next, our goal is to understand the behavior of our mitigation strategies when deployed on a large-scale real network topology. Our ISP topology is based on a modified version of Rocketfuel's AT\&T topology~\cite{rocketfuel}.
%In order to approximate the general structure of the Internet,
% (scale-free structure, customer-provider, and peer-to-peer relations)
We extract the largest connected component comprising of 562 nodes from this original topology and separate the nodes into three categories: clients, gateways, and backbones. Nodes having degree less than four are classified as clients (344 red nodes as shown in Fig.~\ref{fig:large-scale}), nodes directly connected to clients are classified as gateways (109 green nodes), and the remaining nodes as classified as backbones (109 blue nodes). 
%(To ensure that paths in the topology are ``valley-free,'' we augmented the topology with necessary backbone-to-backbone links.) 
We assign bandwidth and  delay values to links based on their type---both values are random numbers within the respective ranges as shown in Table~\ref{tab:large-scale}. We experiment with placing the data producer at both a gateway node as well as backbone node, which we randomly pick for each simulation run. Similar to the binary tree topology experiments, we fix the number of malicious nodes at approximately 40\% (140 out of 344 client nodes in the topology) and randomly pick these nodes for each simulation run. We conduct 10 simulation runs for each mitigation algorithm, with the attack duration spanning a 5-minute interval.

\begin{figure}[htbp]
  \centering
  \vspace{-.1cm}\includegraphics[scale=0.15,angle=90,height=3.5cm,width=8cm]{7018-r0}
  \caption{Internet-like topology: 344 client routers (red), 109 gateway routers (green), 109 backbone routers (blue)}\vspace{-.2cm}
  \label{fig:large-scale-topo}
\end{figure}

\begin{table}[htbp]
\centering
\caption{Large-scale topology link bandwidth and delay ranges}
\label{tab:large-scale}
\begin{tabular}{|l||c|c||c|c|}
  \hline
  \multirow{2}{*}{\bf Link type} &  \multicolumn{2}{|c||}{\bf Delay} &  \multicolumn{2}{|c|}{\bf Bandwidth} \tabularnewline
  \cline{2-5}
                        &  Min & Max                       &  Min & Max \tabularnewline
  \hline \hline
  Backbone--Backbone    & 5~ms & 10~ms   & 40~Mbps & 100~Mbps \tabularnewline
  \hline
  Gateway--Backbone,    & \multirow{2}{*}{5~ms} & \multirow{2}{*}{10~ms}   
                        & \multirow{2}{*}{10~Mbps} & \multirow{2}{*}{20~Mbps} \tabularnewline
  Gateway--Gateway      & & & & \\
  \hline
  Client--Gateway       & 10~ms & 70~ms   & 1~Mbps  & 3~Mbps \\
  \hline

\end{tabular}
\end{table}

%Priya: Leaving out this in the interest of space...
%Topological location of the data producer plays a key role in its resilience to Interest flooding attacks. For a data producer that %is connected to a client node via a low-bandwidth link, even a small number of junk Interests can impact services for legitimate %users. For a producer located at the backbone with rich connectivity through many high-bandwidth links, an attack might not %be as severe as a majority of legitimate users might not be on the attack path. 


% The results for all attack mitigation algorithms and all runs are aggregated in Fig.~\ref{fig:small-scale attack progress}, where Y-axis represents a minimum and maximum range for observed Interest satisfaction percentages among all nodes and all simulation runs.
% A short and simplistic summary of the results is that the first two attack mitigation methods do not work at all, and the last two are working quite good.

In Fig.~\ref{fig:large-scale}, we summarize our results aggregated over 10 simulations runs for each mitigation algorithm for the scenario, where the data producer is placed at a gateway node. We observe similar results for the data producer placed at the backbone node as well. As in the case of the binary-tree topology experiments, token bucket with per interface fairness is the most ineffective algorithm and satisfaction-based pushback is the most effective one.   Interest satisfaction percentage for legitimate users are approximately 25\% and almost 100\% respectively for these two mitigation methodologies.

%
%The evaluation results,\footnote{Note that for larger-scale experiments we reduced attack window to 15~minutes} summarized in Fig.~\ref{fig:large-scale}, show that performance of the token bucket with per interface fairness and satisfaction-based pushback algorithms are about at the same level as in small-scale evaluations (Fig.~\ref{fig:small-scale}), but with larger variations of minimum and maximum instantaneous satisfaction rates.

\begin{figure}[tbh]
 \centering
 \includegraphics[scale=0.8]{paper-topo-7018-gw/7018-r0-good-0-producer-gw}
 \vspace{-.3cm}\caption{Satisfaction ratio dynamics during the attack for large-scale topology with 40\% attackers)}\vspace{-.4cm}
 % producer on a gateway node
 \label{fig:large-scale}
\end{figure}

Satisfaction-based Interest acceptance algorithm, which was very effective for binary-tree topology, is completely ineffective when deployed in a larger realistic topology. For the duration of the attack, legitimate users experience poor quality of service with only 25\% of their Interests being satisfied and continue to experience degraded service long after the attack has stopped. This poor performance, as detailed in  in Section~\ref{sec:probabilistic}, is due to the fact that each router in the path makes an independent, uncoordinated decision on whether to forward or drop an Interest. In the case of the larger-topology, with much higher average hop count, Interest packets from legitimate users have a very low probability of reaching the data producer, resulting in poor Interest satisfaction statistics, which in turn leads to further penalization of new Interests from them.

To summarize, in all of our simulations, the satisfaction-based pushback algorithm is the most effective technique as it restricts malicious Interests from even entering the network. 
%The only short periods of time when malicious Interests are getting admitted to the network is when routers have either no prior knowledge about per-interface satisfaction ratios (the initial period of the attack) or such knowledge becomes stale (statistics decaying during the attack). As soon as the knowledge is obtained or refreshed, the service for legitimate users returns to norm.


% Alex: Anything else here?

% Alex: I also experimented with placing producer at the backbone, getting slightly better results for all algorithms.  Though I'm not sure there is any value to put those results in the paper

% \input{simulation-emulation.tex}

\subsection{Limitations}
%{\color{red} I gave up the idea of seperate discussion section after trying for some time, as given the space limitation, there is no way to write a reasonably comprehensive and  broad discussion section that justifies a separate section. Instead, I decided to have a scoped down version here that confesses upon the limiations of our evaluations only. Whoever has time (I need to sleep few hours), please go ahead and write 1-2 paragraphs as I outlined below. -Ersin}

%This section should roughly say: Our results show that the two features, namely the symmetric traffic and stateful routing, give NDN routers the ability to observe and characterize traffic in real time. Through our evaluations, we demonstrated that a mitigation algorithm that leverages such ability has great potential in mitigating various DDoS attacks that could otherwise have grave effect on the network. However, as the first step in exploring the problem and the solution space, this paper has obvious limitations: (1) We assume a simple attacker model that would be most effective in vanilla NDN and keep it static during our evaluations. Although it is a valid and important step in showing the effectiveness of a particular mitigation approach, the next natural step is evaluating the above described solutions with more sophisticated and adaptive attackers. (2)   Although most (such as single-path routing, no-caches in the network, single homed victim, etc) are aimed to test the proposed solutions under worst-case scenario, we made many assumptions in simulations/evaluations about the configurations, topology and the traffic that maybe poor-representative of realistic conditions. (3) As NDN being an ongoing research effort itself, our evaluations fully depend on simulations and done over a snapshot of its codebase.       

% The main contribution of the paper and this section in particular is a proof that two inherent properties of NDN architecture, namely the symmetric traffic and stateful forwarding, give NDN routers the ability to characterize traffic and react in real time. 
% We demonstrated that satisfaction-based pushback algorithm, leveraging this ability, has great potential in mitigating various DDoS attacks that could otherwise have a grave effect on the network. 
% However, as the first step in exploring the problem and the solution space, our paper has obvious limitations.
% First, we assumed a simple attacker model that would be most effective in vanilla NDN and keep it static during our evaluations. 
% Although it is a valid and important step in showing the effectiveness of a particular mitigation approach, the next natural step that we are leaving out for future work is evaluating the above described solutions with more sophisticated and adaptive attackers. 
% Second, while aiming to test the designed algorithms under worst-case conditions, the future work needs to address behavior in more realistic scenarios, including investigation of multi-path routing, in network caches, as well as multi-homed victims.

This paper is a first step in understanding the impact of Interest flooding attacks in NDN and exploring the solution space. 
While designing our mitigation algorithms, we exploit two key features of NDN architecture, namely routers maintaining state about the Interests they have forwarded and Data traffic taking the reverse path of the Interest traffic. 
We test the efficacy of our algorithms by simulating them on both a binary-tree topology designed to test the worst-case effectiveness of our algorithms as well as on a realizing ISP-based topology designed to provide insights of our algorithms' behavior when deployed on a real network. 
While our results are promising and show a great potential in mitigating Interest flooding DDoS attacks, there are certain limitations which should be addressed in future research. 

First, in our evaluations we used a simple and static attacker model---attackers send junk Interests as fast as possible. 
In the future work, we plan to explore the impact of models where the attackers are more sophisticated and dynamically adapt their behavior and junk Interest sending patterns based on the network reaction. 
Second, we made an assumption that Interests are not satisfied by an intermediate router's cache and always forwarded all the way to the producer.  
The future work needs to study impact of Interest flooding attack in more realistic scenarios, including investigation effects of multi-path routing and presence of in network caches.
% We also ignored NDN's strategy layer that routes around failure and congestion in the network. 
% In future work, we plan to study the impact of turning on these features. 
Finally, we also plan to perform more extensive simulations on other realistic Internet-like topologies and traffic patterns.



%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "paper"
%%% End: 
