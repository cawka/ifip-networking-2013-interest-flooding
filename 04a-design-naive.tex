\section{Interest flooding mitigation methods}
\label{sec:design}

% Points what should be here:
% - What can be done (in general) to mitigate flooding attack
% - Which building blocks NDN architecture gives to mitigate Interest flooding attacks: Interest limits, ability to measure Interest satisfaction performance (Interest satisfaction stats)
% - Methods to set these limits: static/dynamic
% - Methods how limits can be applied: best-effort (fifo), "fair" queuing, probabilistic
% - Reference to caching: we don't consider it here, but caching provides additional level of protection, especially for certain types of attacks

% Our definition of attack mitigation is that good clients are still able to access data on the producer.

In this section we present several algorithms to mitigate Interest flooding attacks in NDN.  Our mitigation strategies feature varying degrees of implementation complexity and effectiveness---the higher the implementation complexity, the more effective is the algorithm against Interest flooding attacks. We start by describing our simple strategies and use the insights and lessons learnt from the deployment of these techniques to inform and design more effective mitigation techniques that can work well in a variety of attack scenarios.

%   - Naive approach to Interest Limits (that is called physical limits everywhere else)
%     Example how this can be implemented in a simple way
%     Baseline solution
%   - Interest limits with "fair" queuing
%     Improving problem of simple limits (no single face can dominate), but doesn't solve the proble

% - Attack mitigation
%   - Per-incoming interface Interest statistics

%   - Dynamic Interests limit adjustments

%   - Probabilistic Interest accept

%The fact that each Data packet takes the reverse path of the corresponding Interest packet allows intermediate routers to match a received Data packet to the corresponding Interest packet and %thus determine which Interest packets were satisfied. As we describe in the rest of this section,  NDN routers can exploit this information to make informed decisions on which Interest packets to %forward, how many Interest packets to forward, and thus effectively defend against DDoS attacks.

%Our methods to mitigate Interest flooding attack rely on the fundamental principle of the NDN architecture: the flow balance between Interest and Data packets: one Interest packet (the only communication initiator) can be satisfied with at most one Data packet.
%Because NDN is host-to-host architecture (as opposed to end-to-end in the current IP Internet), the flow balance principle allow any entity on the network, end-hosts and routers, control what and how much Data they want to receive.
%Therefore, any node can limit the number of forwarded Interests, effectively limiting the amount of the retrieved Data.
%At the same time, each forwarded Interest can be used to build up various data plane performance statistics, such as per-incoming interface ratios of satisfied Interests.

%\subsection{Na\"{i}ve attack mitigation}

%We start with a couple of naive strategies that can be used to migitate attacks in an NDN network and describe the pitfalls associated with these strategies.

% In a normal network operation, the size of Interests packets is supposed to be significantly smaller than the size of the requested Data.

% All communication in NDN network is host-to-host and receiver-driven.

An obvious and na\"ive solution to defend against Interest flooding attacks is to restrict the number of Interests that are forwarded in the network. To this end, we exploit a 
 fundamental principle of NDN architecture---flow balance between Interest and Data packets. The flow balance refers to the fact that one Interest can be satisfied by at most one Data packet. This principle allows intermediate routers to control the inbound Data traffic by controlling the number of outstanding Interests in the network. 
One simple implementation technique  is for an NDN router to limit the number of forwarded Interests out of each interface based on the physical capacity of the corresponding out interface. This technique is a slight modification of the well-known {\it Token Bucket} algorithm that is currently widely used in packet switched networks. Analogous to the {\it Token Bucket} algorithm, NDN routers keep track of the amount of Data requested that can fully utilize the downstream link (estimated from the number of Interests it forwarded) and once the link capacity limit has been reached, they no longer forward new incoming Interests. Ideally, the number of tokens (the pending \emph{Interests Limit}) for each link will be proportional to the link's bandwidth-delay product (BDP)~\cite{tcp-survey}. We can formalize this value as follows:
% With the objective to request as many Data packets, as downstream link can pump through, we are getting the following equation for Interest limit:
%
\begin{equation}
\small \mathrm{Interest\ Limit} = Delay\ [s] \cdot \frac{\mathrm{Bandwidth\ [Bytes/s]}}{\mathrm{Data\ packet\ size\ [Bytes]}}
\end{equation}

In the above equation, \emph{Delay} is the expected time of Interest being satisfied and \emph{Data packet size} is the size of the returned Data packet.
Although both these values are not known a priori, it is not really necessary to use their exact values.
One can simply set the pending Interest limit based on the average values of round trip time and observed Data packet size, as the network buffers can smooth out most of the network fluctuations.

This {\it Token Bucket} approach might be exceptionally retrictive in forwarding Interests---not all Interests will result in a Data packet---thus underutilizing the network. However, the biggest drawback of the algorithm is that it can be used as an effective mechanism to carry out denial of service attacks. If a router has utilized all its tokens to forward malicious Interests, it can no longer forward incoming Interests from legitimate users till the pending malicious Interests start to expire. One way to get around this issue is to impose a per interface limit, so that malicious Interests are not allowed to entirely consume the limits of a specific interface. We describe this technique in greater detail below.

%That is, if it is known that the amount of already requested data ($=$~amount of forwarded Interests) can fully utilize the downstream link, an NDN node---either an end-user or an NDN router---has absolutely no point in forwarding new incoming Interests and creating corresponding PIT entries.
%For example, if a router A on Fig.~\ref{fig:flooding example} already forwarded 125 Interests requesting 1000-byte Data packets, any new incoming Interests can be almost safely dropped, provided the link capacity between A--B is 100~Mbps and delay is 10~ms.
%In other words, 125 Data packets returned by router B will fully utilize the link ($125 \times 1000 \mathrm{~bytes} \approx 10\mathrm{~ms} \times 100\mathrm{~Mbps}$) and any excess Data would be dropped.
%
%\subsubsection{\textbf{Interest limits (physical limits)}}
%\label{sec:physical limits}
%
%\input{algos/physical-limits.tex}

%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{\textbf{Token bucket with per interface fairness}}
\label{sec:queuing}

To address the lack of fairness associated with the na\"ive {\it Token Bucket} algorithm, we modify it to ensure that the Interests forwarded by a router on each interface represent a fair mix of Interests received from neighboring interfaces. For example, in Fig.~\ref{fig:flooding example} router A can ensure that the tokens associated with Interests sent out on interface {\texttt eth2}  are fairly distributed across incoming interfaces \texttt{eth0} and \texttt{eth1}. 
%Due to the expected small volume of Interests, we cannot merely rely on network buffers to perform statistical multiplexing of Interests, as they would almost never be %buffered.
%At the same time, until bag of tokens is not empty, there is no reason to delay Interest forwarding, as we do not known how many and from which interfaces Interests %will arrive in the future.
In order to achieve our goal of ensuring ``fair'' mixing of Interests from all neighboring interfaces, 
%, we implement an additional features to support buffering of Interests, if they cannot be immediately forwarded. 
we extend the Pending Interest Table to support flagging of Interests that cannot be immediately forwarded and implement hierarchical queues for each interface (see Fig.~\ref{fig:queueing}). 
This mechanism is essentially a class based queuing~\cite{floyd1995link}, with classes for each outgoing/incoming interface.
%As an alternative to hierarchical queues, one can also use an approach based on virtual time. For details, please see ~\cite{zhang1990virtual}.
We note that unlike normal queuing, Interest queues do not actually store a packet, but merely a bi-directional pointer to the existing PIT entry.
Thus, a PIT entry can be quickly updated when the Interest is actually forwarded; further the element can be quickly removed from the queue when the Interest expires.

%For the buffering part, we can reuse Pending Interest Table, with a small extension to support flagging of the Interests that cannot be forwarded immediately (see example on Fig.~\ref{fig:queueing}). 
%As for the mixing part, we need an additional fair queuing mechanism, which can be implemented in a form of hierarchical queues (on Fig.~\ref{fig:queueing})\footnote{This essentially is a class based queuing, with classes for each outgoing/incoming interface.} or using virtual time approach~\cite{zhang1990virtual}. 

\begin{figure}[thb]
  \centering
  \includegraphics[scale=0.65]{queue}
  \vspace{-1cm}
  \caption{Interest queuing: if tokens are unavailable, the router creates a PIT entry, but instead of forwarding, it enqueues the Interest}
  \label{fig:queueing}
\end{figure}

We present a formalized description of this algorithm in Pseudocode~\ref{alg:queuing}. 
By setting appropriate queue sizes we can control the amount of physical resources utilized at a router (such as memory and computation power). 
It is also important to set apprpriate value for how long an Interest can be enqueued. 
If an Interest is enqueued for a long time, by the time it is dequeued and appropriately forwarded, the resulting Data packet might not be valid due to state expiration at the downstream routers. 
For our evaluations we chose to enqueue Interests up to 10\% of their original lifetime.
% We believe that implementing additional mechanisms on each pair of communicating routers to keep the Interests from getting stale would mitigate this issue, though the details are beyond the scope of this paper.
% Alex: I don't believe there is a need for separate discussion about "freshness", as we already introduced concept of lifetime
% {\color{red} \it Priya:  We need to  touch upon the Interest freshness issue in the NDN overview section; else we should get rid of this bit.}

%It should be noted that enqueued Interests should not be kept in the queue for a prolonged period of time.
%Otherwise, by the time the Interests reaches the Data, the state could have been long expired downstream, effectively making such an Interest useless.
%Additional mechanisms of pair-wise agreements between NDN routers and periodic Interest refresh can solve this particular problem, but it is out of the scope of the present paper.

%The algorithm extends the base Physical limits algorithm by enabling queuing when the bag of tokens is empty (lines 7--10), as well as by triggering an action (lines 16--21), when a token becomes available and enqueued Interest can be finally forwarded.
%At the same time, the algorithm limits number of Interests allowed in a queue, constraining memory usage increase by at most a constant factor, compared to the base Physical limits algorithm (i.e., memory attack on routers are still unfeasible). 


\floatname{algorithm}{Pseudocode}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{algorithm}[h]
\footnotesize
\caption{\small Token bucket with per interface fairness}
\label{alg:queuing}
\begin{algorithmic}[1]
\For{\textbf{each} interface \textbf{if}}
    \State{$L_{if} \leftarrow$ Interest Limit according to (1)}
    \State{$O_{if} \leftarrow 0$} \Comment{Outstanding Interests on interface \textbf{if}}
\EndFor

\vspace{0.1cm}

\Function{OutInterest}{Interest \textbf{i}, InInterface \textbf{in}, OutInterface \textbf{out}}
    \If{$L_{out} - O_{out} > 0$} \Comment{\textbf{out} is under limit cap}
        \State $O_{out} \leftarrow O_{out} + 1$  \Comment{``borrow'' a token from the bucket}
        \State add \textbf{out} to PIT entry and forward \textbf{i} to \textbf{out}
    \Else
        \State Queue $q \leftarrow out$.GetSubQueue($in$)
        \If{$Size(q) < L_{out}$}
           \State $q$.PushInterest($i$)
           \State add \textbf{out} to PIT entry, and link PIT entry with the queue
        \Else
           \State drop Interest
        \EndIf
    \EndIf
\EndFunction

\vspace{0.1cm}

\State{} \Comment{\textit{Whenever $L_{out} - O_{out}$ becomes larger than zero}}
\Function{TokenBecomesAvailable}{}
    \State Queue $q \leftarrow$ $out$.GetRoundRobinSubQueue 
    \State Interest $i \leftarrow$ $q$.PopInterest
    \State update PIT entry and Forward($i$, $out$)
\EndFunction

\vspace{0.1cm}

\Function{InData}{Data \textbf{d}}
   \State lookup PIT entry \textbf{p} for data \textbf{d}
   \For{\textbf{each} outgoing interface \textbf{out} in \textbf{p}}
        \State $O_{out} \leftarrow O_{out} - 1$ \Comment{``return'' token}
   \EndFor
\EndFunction

\vspace{0.1cm}

\Function{Timeout}{PIT entry $p$}
   \For{\textbf{each} outgoing interface \textbf{out} in \textbf{p}}
        \State $O_{out} \leftarrow O_{out} - 1$ \Comment{``return'' token}
   \EndFor
\EndFunction


\end{algorithmic}
\end{algorithm}


As we show in Section~\ref{sec:evaluation}, this algorithm provides partial relief from the Interest flooding attacks, allowing legitimate users to successfully fetch Data for 15--20\% of their expressed Interests. 
We note that while this algorithm might be reasonable for ensuring fairness in an NDN network, it is ineffective in protecting legitimate users from malicious attackers. 
Malicious attackers are able to successfully thwart access to content for legitimate users by sending a relatively modest volume of Interests.


%At the same time, the Physical limits with or without fair queueing allows attackers to send a relatively small volume of Interests in order to significantly impact service for the legitimate users.
%Therefore, to successfully solve the problem, we need a fundamentally different, more intelligent approach, allowing localization of the attack traffic as close as possible to the attack origin.


%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%

The key drawback of the {\it Token bucket with per interface fairness} algorithm is that it admits Interests from malicious users. A sizeable percentage of these malicious Interests are forwarded all the way to content producers, thereby utilizing scarce network resources and reducing resources available to serve legitimate users.  This algorithm attempts to ensure that each interface does not forward more than its fair share of Interests, but in doing so, it drops both legitimate Interests as well as malicious Interests. For any strategy to be effective in defending against Interest flooding attacks, it must be able to detect and effectively drop only malicious requests for content. `Good' Interests from legitimate users must be admited and forwarded appropriately. The key question is how can we devise mitigation algorithms that allow a router to distinguish between `good' and `bad' Interests? 

%One can try a black- or whitelisting approach. However, besides the fact that source black- and whitelisting cannot work in %NDN as it does not feature source addresses, it requires extraneous knowledge to classify the incoming Interests.

%Priya: I have added the below point specifically to point out that a router cannot determine from the prefix name alone whether /parc is good  or bad...
  
In NDN one cannot easily distinguish a `good' prefix from a `bad' one. Content producers must be able to support dynamic generation of Data packets to satisfy incoming Interest packets---thus, an Interest that cannot be satisfied by matching Data from any intermediate router's cache is necessarily forwarded to the producer for possible dynamic Data packet generation. 
Thus intermediate routers cannot determine if the prefix is `good' or `bad' based on the prefix name alone---DDoS mitigation techniques that rely on whitelisting or blacklisting of certain namespaces  will be inefficient and likely ineffective. 

% Alex: I'm not sure that this part is relevant... The point I see is that blacklisting and whitelisting is not 100% effective, but it can be used in both worlds

% In today's host-based Internet architecture where DDoS mitigation techniques rely on blacklisting of ``dark'' IP prefixes or whitelisting of good IP prefixes.
% Unlike IP, in NDN one cannot easily distinguish a `good' prefix from a `bad' one. 
% Content producers must be able to support dynamic generation of Data packets to satisfy incoming Interest packets---thus, an Interest that cannot be satisfied by matching Data from any intermediate router's cache is necessarily forwarded to the producer for possible dynamic Data packet generation. 
% Thus intermediate routers cannot determine if the prefix is `good' or `bad' based on the name alone---DDoS mitigation techniques that rely on whitelisting or blacklisting of certain namespaces  will be inefficient and likely ineffective. 



%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "paper"
%%% End: 
